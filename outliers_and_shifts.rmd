---
title: 'Automated outlier and structural shift detection'
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook:
    df_print: paged
    toc: yes
    toc_depth: 5
always_allow_html: yes    
    
editor_options: 
  chunk_output_type: console
---


# Setup code - run all of these chunks
<!-- setup chunk -->
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
```


```{r system_specific_values, include=FALSE}
# ddir <- "C:/Users/donbo/Dropbox/DSRIP TSA_CA Team Info/chris_workflow/data/"
team_dir <- "C:/Users/donbo/Dropbox/DSRIP TSA_CA Team Info/"

chris_source_dir <- paste0(team_dir, "CMA Files/dsrip/chris_workflow/data/") # not used now

don_dir <- paste0(team_dir, "Don's Files/data/don/")
chris_dir <- paste0(team_dir, "Don's Files/data/chris_frozen/")

```


```{r globals, include=FALSE}
dsrip_start <- as.Date("2015-07-01")
```


```{r libraries, include=FALSE}
library("magrittr")
library("plyr") # needed for ldply; must be loaded BEFORE dplyr
library("tidyverse")
options(tibble.print_max = 60, tibble.print_min = 60) # if more than 60 rows, print 60 - enough for states
# ggplot2 tibble tidyr readr purrr dplyr stringr forcats

library("scales")
library("hms") # hms, for times
library("lubridate") # lubridate, for date/times
library("vctrs")

library("grDevices")
library("knitr")
library("kableExtra")

library("btools")

library("DT")

library("zoo") # for rollapply

library("broom") # for automating the cleanup of complex output
library("tsoutliers")

```


```{r functions_general, include=FALSE}
ns <- function(df) {names(df) %>% sort}


msr_name <- function(msr_id, measures_df=measures) {
  # return the measure name MSR_RESULT_NAME for a given measure id MSR_RESULT_ID
  # requires as input a dataframe that has both MSR_RESULT_ID and MSR_RESULT_NAME
  tibble(MSR_RESULT_ID=msr_id) %>%
    left_join(measures_df) %>%
    .$MSR_RESULT_NAME
}


pps_wrap <- function(PPS_ID, PPS_NAME, maxlen=100, wrap=25) {
  name <- str_sub(PPS_NAME, 1, maxlen)
  paste0(str_pad(PPS_ID, 2, pad="0"), ": ", name) %>% # zero-pad for better sorting
    str_wrap(wrap)
}


```


# START OF ANALYSIS -- with combined PPS/Statewide data
```{r getdata, include=FALSE}
# get previously created data
ppsdf <- readRDS(paste0(don_dir, "ppsall_ma.rds")) # monthly pps and statewide data, long
measures <- readRDS(paste0(don_dir, "measures.rds"))
ppsnames <- readRDS(paste0(don_dir, "ppsnames.rds"))
measures

# to be on the safe side make sure ppsdf is ungrouped and sorted
ppsdf <- ppsdf %>%
  ungroup %>%
  arrange(PPS_ID, MSR_RESULT_ID, PER_END_DT) 

```


```{r include=FALSE}
# functions to identify outliers in a vector and return a data frame of outlier locations

get_level_shift <- function(vec, crit.val=2.75, delta.val=0.7){
  # function to identify different level shifts
  #   vec is a numeric vector (sorted by time sequence)
  #   the return will be outdf, a data frame with information on outliers in the data, including their positions
  
  # kinds of outliers
  # An Additive Outlier (AO) represents an isolated spike
  # A Level Shift (LS) represents an abrupt change in the mean level
  # A Transient Change (TC) represents a spike that takes a few periods to disappear
  
  # focus on finding points that meet level-shift criteria
  
  # the lower crit.val is, the more sensitive this is to outliers (the more likely to find them)
  # the default is NULL; values below about 3 seeem useful
  
  # lower delta.val also tends to find more outliers; 0.7 is default
  
  make_empty_row <- function(vec){
    # define 1-row data frame to return if we have bad data or bad results
    outdf <- tibble(nobs=length(vec), type=factor(NA_character_), ind=NA_integer_, coefhat=NA_real_, tstat=NA_real_)
    outdf
  }
  
  if(length(vec) < 48) return(make_empty_row(vec)) # too few observations
  
  tsobj <- ts(vec, frequency=1) # the tso function requires a time-series object
  
  inner.loop <- 10
  outer.loop <- 6
  
  # get each of the 4 kinds of outliers separately, rather than all at once - I have found this to work well
  out <- tsoutliers::tso(tsobj, types = "LS", maxit.iloop = inner.loop,
                         cval = crit.val,
                         tsmethod="arima",
                         args.tsmethod = list(order=c(0, 1, 1)))

  if(nrow(out$outliers)==0) return(make_empty_row(vec))
  
  # we only get here if we have an acceptable result
  outdf <- out$outliers %>% 
    mutate(nobs=length(vec)) %>%
    select(nobs, type, ind, coefhat, tstat) %>% 
    as_tibble
  
  return(outdf)
}


get_level_shift_trapping <- function(vec, crit.val=2.75, delta.val=0.7){
  # function to identify different level shifts
  #   vec is a numeric vector (sorted by time sequence)
  #   the return will be outdf, a data frame with information on outliers in the data, including their positions
  
  # this is a robust version that looks for several kinds of problems that could occur in the data:
  #  - an input vector that has too few values to run through the  outliers routine
  #  - an error that causes the arima optimization routine
  #     to fail (I am not sure I know when this occurs, but it is rare)
  #  - a problem in which the arima optimzation routine runs but does not return a data frame of outlier locations
  #     presumably something was not right in the data
  #  - zero ouliers found - not really a problem, we just need to exit gracefully
  
  # kinds of outliers
  # An Additive Outlier (AO) represents an isolated spike
  # A Level Shift (LS) represents an abrupt change in the mean level
  # A Transient Change (TC) represents a spike that takes a few periods to disappear
  
  # focus on finding points that meet level-shift criteria
  
  # the lower crit.val is, the more sensitive this is to outliers (the more likely to find them)
  # the default is NULL; values below about 3 seeem useful
  
  # lower delta.val also tends to find more outliers; 0.7 is default
  
  make_empty_row <- function(vec){
    # define 1-row data frame to return if we have bad data or bad results
    outdf <- tibble(nobs=length(vec), type=factor(NA_character_), ind=NA_integer_, coefhat=NA_real_, tstat=NA_real_)
    outdf
  }
  
  # I'm not sure what to set as the minimum vector length but for now I use 3 years
  if(length(vec) < 36) return(make_empty_row(vec)) # too few observations
  
  # now we're ready to start
  tsobj <- ts(vec, frequency=1) # the tso function requires a time-series object
  
  inner.loop <- 10
  outer.loop <- 6
  
  # we have to put the tso function into a function that calls it and looks for an error
  runtso <- function(tsobj) {
    out <- tryCatch(
      {
        # run the function
        tsoutliers::tso(tsobj, types = "LS", maxit.iloop = inner.loop,
                        cval = crit.val,
                        tsmethod="arima",
                        args.tsmethod = list(order=c(0, 1, 1)))
        },
      # now we can decide what to do if we cautht an error
      error=function(e) {
        return(make_empty_row(vec)) # exit with proper output
        }
      )
    # if we get here the arima optimization ran but that doesn't necessarily mean the results are good
    # we'll check that further below
    return(out)
  }
  outlist <- runtso(tsobj)
  
  # the "outliers" data frame may not exist in outlist so we have to check for that - not sure when this will happen
  if(!exists("outliers", where=outlist)) return(make_empty_row(vec))
  
  # if we get here, arima ran AND we have an outliers data frame, but it may not have any rows
  if(nrow(outlist$outliers)==0) return(make_empty_row(vec))
  
  # we only get here if we have an acceptable result so we add nobs and return the outliers data frame
  outdf <- outlist$outliers %>% 
    mutate(nobs=length(vec)) %>%
    select(nobs, type, ind, coefhat, tstat) %>% 
    as_tibble
  
  return(outdf)
}



```


# test the function on some known situations - several smooth, several with breaks
```{r eval=FALSE}
# create test data sample of vectors with different characteristics, based upon in spection of plots
defs <- tribble(
  ~vectype, ~MSR_RESULT_ID, ~PPS_ID,
  "smooth", "AAPC20RES", 25,
  "smooth", "CAPC12MRES", 14,
  "smooth", "PDI14RES", 36,
  "break", "AMRRES", 40, # 1 break
  "break", "PPVRES", 33,
  "break-sharpfall", "CAPC12RES", 36,
  "outliers2", "AMMACUTRES", 48,
  "break", "AAPC20RES", 16,
  "break", "AAPC20RES", 19,
  "break", "AAPC45RES", 34,
  "break", "AMRRES", 52
) %>%
  mutate(groupnum=row_number()) %>%
  left_join(measures %>% select(MSR_RESULT_ID, MSR_RESULT_NAME)) %>%
  left_join(ppsnames)
defs
ns(defs)

test_data <- ppsdf %>% 
  select(MSR_RESULT_ID, PPS_ID, PER_END_DT, time, PER_END_DT, MSR_RESULT) %>%
  right_join(defs, by=c("MSR_RESULT_ID", "PPS_ID"))
ns(test_data)
glimpse(test_data)

fls <- function(df, crit.val) {get_level_shift_trapping(df$MSR_RESULT, crit.val = crit.val)}

d <- test_data %>%
  nest(data=c(PER_END_DT, time, MSR_RESULT)) %>%
  mutate(out=map(data, fls, crit.val=4.5))
d

outdf <- d %>%
  unnest(out, keep_empty = TRUE)
outdf

vlines <- outdf %>%
  filter(!is.na(ind)) %>%
  select(groupnum, MSR_RESULT_ID, PPS_ID, idname, ind) %>%
  mutate(time=ind - 13)
vlines

brks <- c(seq(0, -30, -3) %>% rev, seq(3, 60, 3))
p <- test_data %>%
  # filter(groupnum %in% c(4, 5, 8)) %>%
  ggplot(aes(time, MSR_RESULT)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks=brks) +
  geom_vline(xintercept = 1, colour="blue", linetype="solid") +
  geom_vline(xintercept = 12, colour="blue", linetype="dashed") +
  geom_vline(aes(xintercept=time), colour="red", data=vlines) +
  theme(axis.text.x=element_text(angle=90, vjust=0.5)) +
  theme_bw() +
  facet_wrap(~MSR_RESULT_ID + idname, ncol=3, scales = "free") +
  theme(legend.position = "none")
p
glimpse(test_data)

```


# Analyze level shifts
```{r get_shifts, include=FALSE}

fls <- function(df, crit.val) {get_level_shift_trapping(df$MSR_RESULT, crit.val = crit.val)}
# fls <- function(df, crit.val) {tibble(n=nrow(df))}

ns(ppsdf)

a <- proc.time()
shifts <- ppsdf %>% 
  select(MSR_RESULT_ID, PPS_ID, PER_END_DT, time, PER_END_DT, MSR_RESULT, PPS_NAME, MSR_RESULT_NAME, idname) %>%
  nest(data=c(PER_END_DT, time, MSR_RESULT)) %>%
  mutate(out=map(data, fls, crit.val=4.5))
# may throw warnings that it set some residuals to zero
b <- proc.time()
b - a
glimpse(shifts)

shifts_long <- shifts %>%
  unnest(out, keep_empty = TRUE)
glimpse(shifts_long)

shifts_long %>%
  group_by(MSR_RESULT_ID, PPS_ID) %>%
  summarise(nbreaks=sum(!is.na(ind)), obsmin=min(nobs), obsmdn=median(nobs)) %>%
  group_by(nbreaks) %>%
  summarise(n=n(), obsmin=min(obsmin), obsmdn=median(obsmdn))

shifts_long %>%
  group_by(MSR_RESULT_ID, MSR_RESULT_NAME) %>%
  summarise(n=n(), nbreaks=nbreaks=sum(!is.na(ind))) %>%
  mutate(pctbreaks=nbreaks / n * 100) %>%
  arrange(-nbreaks)

shifts_long %>%
  group_by(MSR_RESULT_ID, MSR_RESULT_NAME, PPS_ID, PPS_NAME, idname) %>%
  summarise(n=n(), nbreaks=sum(!is.na(ind))) %>%
  group_by(MSR_RESULT_ID, MSR_RESULT_NAME) %>%
  summarise(n=n(), breaks=sum(nbreaks>0)) %>%
  mutate(pctbreaks=breaks / n * 100) %>%
  arrange(-breaks)


vlines <- shifts_long %>%
  filter(!is.na(ind)) %>%
  select(MSR_RESULT_ID, PPS_ID, idname, ind) %>%
  mutate(time=ind - 13)
vlines

brks <- c(seq(0, -30, -3) %>% rev, seq(3, 60, 3))
fltr <- expression(PPS_ID %in% c(1:5, 16, 52, 99) & MSR_RESULT_ID %in% c("AAPC20RES", "AMRRES"))

fltr <- expression(MSR_RESULT_ID == "AAPC45RES")
vlines2 <- vlines %>% filter(eval(fltr))
p <- ppsdf %>%
  filter(eval(fltr)) %>%
  ggplot(aes(time, MSR_RESULT)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks=brks) +
  geom_vline(xintercept = 1, colour="blue", linetype="solid") +
  geom_vline(xintercept = 12, colour="blue", linetype="dashed") +
  geom_vline(aes(xintercept=time), colour="red", data=vlines2) +
  theme(axis.text.x=element_text(angle=90, vjust=0.5)) +
  theme_bw() +
  facet_wrap(~MSR_RESULT_ID + PPS_ID, ncol=5, scales = "free") +
  theme(legend.position = "none")
p


```



